{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6350fe-c3b6-471a-9ff5-0db75921a5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/15 13:26:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a657fd-27f4-4e95-bc17-eb951f1fbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaffc74-2008-4baa-87b9-3d22d7c50f9f",
   "metadata": {},
   "source": [
    "## Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f90dbe-63e1-460e-a5b2-114d55f53c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: long (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: long (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: long (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: long (nullable = true)\n",
      " |-- capital_loss: long (nullable = true)\n",
      " |-- hours_week: long (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/sadhana1002/PredictingSalaryClass-Classification/master/adult.csv\"\n",
    "df = sqlContext.createDataFrame(pd.read_csv(url, \n",
    "                                      names=['Age','workclass',\n",
    "                                             'fnlwgt','education',\n",
    "                                             'education_num',\n",
    "                                             'marital',\n",
    "                                             'occupation',\n",
    "                                             'relationship','race',\n",
    "                                             'sex','capital_gain',\n",
    "                                             'capital_loss',\n",
    "                                             'hours_week',\n",
    "                                             'native_country','label']))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd23e757-78d5-4236-b91e-7b00c5739e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+----------+--------------+------+\n",
      "|Age|workclass        |fnlwgt|education |education_num|marital            |occupation        |relationship  |race  |sex    |capital_gain|capital_loss|hours_week|native_country|label |\n",
      "+---+-----------------+------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+----------+--------------+------+\n",
      "|39 | State-gov       |77516 | Bachelors|13           | Never-married     | Adm-clerical     | Not-in-family| White| Male  |2174        |0           |40        | United-States| <=50K|\n",
      "|50 | Self-emp-not-inc|83311 | Bachelors|13           | Married-civ-spouse| Exec-managerial  | Husband      | White| Male  |0           |0           |13        | United-States| <=50K|\n",
      "|38 | Private         |215646| HS-grad  |9            | Divorced          | Handlers-cleaners| Not-in-family| White| Male  |0           |0           |40        | United-States| <=50K|\n",
      "|53 | Private         |234721| 11th     |7            | Married-civ-spouse| Handlers-cleaners| Husband      | Black| Male  |0           |0           |40        | United-States| <=50K|\n",
      "|28 | Private         |338409| Bachelors|13           | Married-civ-spouse| Prof-specialty   | Wife         | Black| Female|0           |0           |40        | Cuba         | <=50K|\n",
      "+---+-----------------+------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+----------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d31aaf-bc6c-4728-a282-7ed556a2809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: float (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: float (nullable = true)\n",
      " |-- capital_loss: float (nullable = true)\n",
      " |-- hours_week: float (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import all from `sql.types`\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df \n",
    "# List of continuous features\n",
    "CONTI_FEATURES  = ['age', 'fnlwgt','capital_gain', 'education_num', 'capital_loss', 'hours_week']\n",
    "# Convert the type\n",
    "df = convertColumn(df, CONTI_FEATURES, FloatType())\n",
    "# Check the dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b0f760f-2dbc-424d-9644-91675a5b1b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "| age|  fnlwgt|\n",
      "+----+--------+\n",
      "|39.0| 77516.0|\n",
      "|50.0| 83311.0|\n",
      "|38.0|215646.0|\n",
      "|53.0|234721.0|\n",
      "|28.0|338409.0|\n",
      "+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('age','fnlwgt').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "632cde92-0908-4ebf-95b8-fb17a5cbd1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=============================================>         (166 + 3) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|    education|count|\n",
      "+-------------+-----+\n",
      "|    Preschool|   51|\n",
      "|      1st-4th|  168|\n",
      "|      5th-6th|  333|\n",
      "|    Doctorate|  413|\n",
      "|         12th|  433|\n",
      "|          9th|  514|\n",
      "|  Prof-school|  576|\n",
      "|      7th-8th|  646|\n",
      "|         10th|  933|\n",
      "|   Assoc-acdm| 1067|\n",
      "|         11th| 1175|\n",
      "|    Assoc-voc| 1382|\n",
      "|      Masters| 1723|\n",
      "|    Bachelors| 5355|\n",
      "| Some-college| 7291|\n",
      "|      HS-grad|10501|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"education\").count().sort(\"count\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3497028-f2fb-4cab-a5d2-cd28b8aa69e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+------------------+-------------+------------------+---------+-----------------+------------+-------------------+-------+------------------+-----------------+------------------+--------------+------+\n",
      "|summary|               age|   workclass|            fnlwgt|    education|     education_num|  marital|       occupation|relationship|               race|    sex|      capital_gain|     capital_loss|        hours_week|native_country| label|\n",
      "+-------+------------------+------------+------------------+-------------+------------------+---------+-----------------+------------+-------------------+-------+------------------+-----------------+------------------+--------------+------+\n",
      "|  count|             32561|       32561|             32561|        32561|             32561|    32561|            32561|       32561|              32561|  32561|             32561|            32561|             32561|         32561| 32561|\n",
      "|   mean| 38.58164675532078|        null|189778.36651208502|         null|  10.0806793403151|     null|             null|        null|               null|   null|1077.6488437087312|  87.303829734959|40.437455852092995|          null|  null|\n",
      "| stddev|13.640432553581363|        null|105549.97769702213|         null|2.5727203320673913|     null|             null|        null|               null|   null|7385.2920848403455|402.9602186489999|12.347428681731829|          null|  null|\n",
      "|    min|              17.0|           ?|           12285.0|         10th|               1.0| Divorced|                ?|     Husband| Amer-Indian-Eskimo| Female|               0.0|              0.0|               1.0|             ?| <=50K|\n",
      "|    max|              90.0| Without-pay|         1484705.0| Some-college|              16.0|  Widowed| Transport-moving|        Wife|              White|   Male|           99999.0|           4356.0|              99.0|    Yugoslavia|  >50K|\n",
      "+-------+------------------+------------+------------------+-------------+------------------+---------+-----------------+------------+-------------------+-------+------------------+-----------------+------------------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f32cd6-b206-4df7-94e0-a1b3e7d5fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      capital_gain|\n",
      "+-------+------------------+\n",
      "|  count|             32561|\n",
      "|   mean|1077.6488437087312|\n",
      "| stddev|7385.2920848403455|\n",
      "|    min|               0.0|\n",
      "|    max|           99999.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('capital_gain').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b630f15-1020-45d9-b0c2-61ac079fa17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+\n",
      "|age_label| <=50K| >50K|\n",
      "+---------+------+-----+\n",
      "|     17.0|   395|    0|\n",
      "|     18.0|   550|    0|\n",
      "|     19.0|   710|    2|\n",
      "|     20.0|   753|    0|\n",
      "|     21.0|   717|    3|\n",
      "|     22.0|   752|   13|\n",
      "|     23.0|   865|   12|\n",
      "|     24.0|   767|   31|\n",
      "|     25.0|   788|   53|\n",
      "|     26.0|   722|   63|\n",
      "|     27.0|   754|   81|\n",
      "|     28.0|   748|  119|\n",
      "|     29.0|   679|  134|\n",
      "|     30.0|   690|  171|\n",
      "|     31.0|   705|  183|\n",
      "|     32.0|   639|  189|\n",
      "|     33.0|   684|  191|\n",
      "|     34.0|   643|  243|\n",
      "|     35.0|   659|  217|\n",
      "|     36.0|   635|  263|\n",
      "+---------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.crosstab('age', 'label').sort(\"age_label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbbd3fd4-db11-4e6b-8405-572247ff7725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'marital',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital_gain',\n",
       " 'capital_loss',\n",
       " 'hours_week',\n",
       " 'native_country',\n",
       " 'label']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('education_num').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "175b4a44-ce98-4101-905c-d31617ffef37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13443"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.age > 40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfdd2538-8e8f-4c62-b9a3-676987ae55e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             marital| avg(capital_gain)|\n",
      "+--------------------+------------------+\n",
      "|             Widowed| 571.0715005035247|\n",
      "| Married-spouse-a...| 653.9832535885167|\n",
      "|   Married-AF-spouse| 432.6521739130435|\n",
      "|  Married-civ-spouse|1764.8595085470085|\n",
      "|            Divorced| 728.4148098131893|\n",
      "|       Never-married|376.58831788823363|\n",
      "|           Separated| 535.5687804878049|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('marital').agg({'capital_gain': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b840752-869b-4a15-9da4-df06c1d0ec8e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70361523-9e8a-4031-9013-6e9ecb6de1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: float (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: float (nullable = true)\n",
      " |-- capital_loss: float (nullable = true)\n",
      " |-- hours_week: float (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- age_square: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# 1 Select the column\n",
    "age_square = df.select(col(\"age\")**2)\n",
    "\n",
    "# 2 Apply the transformation and add it to the DataFrame\n",
    "df = df.withColumn(\"age_square\", col(\"age\")**2)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95a25c88-0b9a-40b4-9a90-c504961f2563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=39.0, age_square=1521.0, workclass=' State-gov', fnlwgt=77516.0, education=' Bachelors', education_num=13.0, marital=' Never-married', occupation=' Adm-clerical', relationship=' Not-in-family', race=' White', sex=' Male', capital_gain=2174.0, capital_loss=0.0, hours_week=40.0, native_country=' United-States', label=' <=50K')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = ['age', 'age_square', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital',\n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "           'hours_week', 'native_country', 'label']\n",
    "df = df.select(COLUMNS)\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26a5b799-4aa6-418d-9a01-047ea809817d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.native_country == 'Holand-Netherlands').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "815caef8-3ba6-4cde-968a-fd50f3048ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:================================================>     (178 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|      native_country|count(native_country)|\n",
      "+--------------------+---------------------+\n",
      "|  Holand-Netherlands|                    1|\n",
      "|            Scotland|                   12|\n",
      "|             Hungary|                   13|\n",
      "|            Honduras|                   13|\n",
      "| Outlying-US(Guam...|                   14|\n",
      "|          Yugoslavia|                   16|\n",
      "|            Thailand|                   18|\n",
      "|                Laos|                   18|\n",
      "|            Cambodia|                   19|\n",
      "|     Trinadad&Tobago|                   19|\n",
      "|                Hong|                   20|\n",
      "|             Ireland|                   24|\n",
      "|             Ecuador|                   28|\n",
      "|              Greece|                   29|\n",
      "|              France|                   29|\n",
      "|                Peru|                   31|\n",
      "|           Nicaragua|                   34|\n",
      "|            Portugal|                   37|\n",
      "|                Iran|                   43|\n",
      "|               Haiti|                   44|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupby('native_country').agg({'native_country': 'count'}).sort(asc(\"count(native_country)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b8be372-2cc1-4b76-bd62-61cc6a7f5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove = df.filter(df.native_country != 'Holand-Netherlands')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f452e-e597-445e-93d5-a341ac0a9c47",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60682cbe-469f-44fb-9ad6-0c96e1220bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------------+-------+----------+-------------+-------------------+----------------+--------------+------+-----+------------+------------+----------+--------------+------+-----------------+-------------+\n",
      "| age|age_square|        workclass| fnlwgt| education|education_num|            marital|      occupation|  relationship|  race|  sex|capital_gain|capital_loss|hours_week|native_country| label|workclass_encoded|workclass_vec|\n",
      "+----+----------+-----------------+-------+----------+-------------+-------------------+----------------+--------------+------+-----+------------+------------+----------+--------------+------+-----------------+-------------+\n",
      "|39.0|    1521.0|        State-gov|77516.0| Bachelors|         13.0|      Never-married|    Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|      40.0| United-States| <=50K|              4.0|(9,[4],[1.0])|\n",
      "|50.0|    2500.0| Self-emp-not-inc|83311.0| Bachelors|         13.0| Married-civ-spouse| Exec-managerial|       Husband| White| Male|         0.0|         0.0|      13.0| United-States| <=50K|              1.0|(9,[1],[1.0])|\n",
      "+----+----------+-----------------+-------+----------+-------------+-------------------+----------------+--------------+------+-----+------------+------------+----------+--------------+------+-----------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Example encoder\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"workclass\", outputCol=\"workclass_encoded\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"workclass_encoded\", outputCol=\"workclass_vec\").fit(indexed)\n",
    "encoded = encoder.transform(indexed)\n",
    "encoded.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f226b893-fa8b-4695-9aee-f0b10b4da934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/15 13:27:00 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(age=39.0, age_square=1521.0, workclass=' State-gov', fnlwgt=77516.0, education=' Bachelors', education_num=13.0, marital=' Never-married', occupation=' Adm-clerical', relationship=' Not-in-family', race=' White', sex=' Male', capital_gain=2174.0, capital_loss=0.0, hours_week=40.0, native_country=' United-States', label=' <=50K', workclassIndex=4.0, workclassclassVec=SparseVector(8, {4: 1.0}), educationIndex=2.0, educationclassVec=SparseVector(15, {2: 1.0}), maritalIndex=1.0, maritalclassVec=SparseVector(6, {1: 1.0}), occupationIndex=3.0, occupationclassVec=SparseVector(14, {3: 1.0}), relationshipIndex=1.0, relationshipclassVec=SparseVector(5, {1: 1.0}), raceIndex=0.0, raceclassVec=SparseVector(4, {0: 1.0}), sexIndex=0.0, sexclassVec=SparseVector(1, {0: 1.0}), native_countryIndex=0.0, native_countryclassVec=SparseVector(41, {0: 1.0}), newlabel=0.0, features=SparseVector(100, {4: 1.0, 10: 1.0, 24: 1.0, 32: 1.0, 44: 1.0, 48: 1.0, 52: 1.0, 53: 1.0, 94: 39.0, 95: 77516.0, 96: 2174.0, 97: 13.0, 99: 40.0}))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "CATE_FEATURES = ['workclass', 'education', 'marital', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in CATE_FEATURES:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()],\n",
    "                                     outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx =  StringIndexer(inputCol=\"label\", outputCol=\"newlabel\")\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "assemblerInputs = [c + \"classVec\" for c in CATE_FEATURES] + CONTI_FEATURES\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "\n",
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(df_remove)\n",
    "model = pipelineModel.transform(df_remove)\n",
    "\n",
    "model.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a0694-dd2b-4c69-ab9a-be123716e229",
   "metadata": {},
   "source": [
    "## Building a classifier: Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cfcd360-9ddd-4e8d-be33-a69d6b33280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "input_data = model.rdd.map(lambda x: (x[\"newlabel\"], DenseVector(x[\"features\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a39ddae4-7f24-4ba6-b840-8c64b1fca565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|\n",
      "|  0.0|[0.0,1.0,0.0,0.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train = sqlContext.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec6d42-6057-41f1-b323-0cf3d1a47b13",
   "metadata": {},
   "source": [
    "## Train/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d049383-c103-43bc-a597-5c38c5e8ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = df_train.randomSplit([.8,.2],seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c93977ae-c37f-4b2f-b6f7-e3506d0d1158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|       19756|\n",
      "|  1.0|        6286|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupby('label').agg({'label': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab572bf4-0875-4987-9b35-4c10db97e808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/15 13:28:02 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/09/15 13:28:02 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import `LinearRegression`\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize `lr`\n",
    "lr = LogisticRegression(labelCol=\"label\",\n",
    "                        featuresCol=\"features\",\n",
    "                        maxIter=10,\n",
    "                        regParam=0.3)\n",
    "\n",
    "# Fit the data to the model\n",
    "linearModel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a0d38ca-89c6-44a5-bcc5-6f6573423a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.06711842757640976,-0.1382593440989027,-0.08503752284026367,-0.16787134606700738,-0.10190090492382443,0.1786781874452196,0.13291092867219895,-0.593080317469945,-0.1941025553800716,-0.08421936167528424,0.21904126326227938,0.4042582885569545,0.008183282453627727,-0.28770726694044835,-0.029773500186749517,-0.3077353796526063,-0.421739052109991,0.533833854430741,-0.3666035918772513,-0.23589338870210932,0.5952773417142875,-0.3728003521194073,-0.40147665005736827,0.31643342627357574,-0.3436437958243061,-0.19524585813307063,-0.26063100869137573,-0.14498892918016495,-0.18446322230206638,0.19242027134862746,-0.06267320128292203,0.2888891343670732,-0.1294838876454583,0.056200468016303254,-0.29523557063314737,-0.21912156864244461,-0.1694515569521391,-0.13439368376565922,-0.30988889427449295,-0.31536836615099295,0.11634597968080496,0.15520089333476134,-0.2826220928546061,0.2553773123930343,-0.1888732469963865,-0.3042726975180536,-0.2475735255919109,0.4326692828297516,-0.06441164575785968,-0.16443578563554387,-0.11192302855958897,-0.24632592533048844,0.1850526303173956,-0.12262660123182512,-0.3381133238485244,-0.23620974623072966,0.00949205424462635,-0.013328099999554172,-0.009263910080995353,-0.25984501388252335,-0.2673613778389866,-0.13690565035116048,-0.11996319266327461,-0.019988472704605187,-0.1686634805134632,-0.39773618654772963,-0.3355617584349126,0.07891256880049625,-0.47841520671870597,-0.30239424312516133,-0.20875534322086975,-0.06259500857740494,-0.1128367473882043,-0.6326856642938362,-0.1418796646194763,-0.2529324033095914,-0.013471757046761077,-0.30559952797547546,-0.6305207916356644,-0.5330483854963113,0.15498610364192558,-0.3024158216067069,-0.32166299670068726,0.010304313243068342,-0.2288406254764987,0.32505706601897083,-0.2924386965670723,-0.2643824217020544,-0.4507124295574176,0.22337325775569672,-0.6156847307207712,-0.32898898748897665,-0.013740672220072612,0.022917867977234385,0.007020639732597195,1.1458282915964615e-07,2.175167382270513e-05,0.026396533629050385,0.00023332582285921771,0.008856273373615534]\n",
      "Intercept: -1.9963235463030422\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(linearModel.coefficients))\n",
    "print(\"Intercept: \" + str(linearModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b2b4f9-454c-4f02-9a56-07f4bb56d203",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ef3f26f-2795-4f6d-a95e-3f1a8aff342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "predictions = linearModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a679bd49-d545-4697-af28-bcd051871173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f30925a5-6eff-4869-a383-7c69c19b694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  0.0|       0.0|[0.92776186638288...|\n",
      "|  0.0|       0.0|[0.95934682271558...|\n",
      "|  0.0|       0.0|[0.84444079151160...|\n",
      "|  0.0|       0.0|[0.85431265538794...|\n",
      "|  0.0|       0.0|[0.89715660422934...|\n",
      "|  0.0|       0.0|[0.87867879585946...|\n",
      "|  0.0|       0.0|[0.85660455179762...|\n",
      "|  0.0|       0.0|[0.59559551795692...|\n",
      "|  0.0|       0.0|[0.80506822160551...|\n",
      "|  0.0|       0.0|[0.75910879318479...|\n",
      "|  0.0|       0.0|[0.51223356814469...|\n",
      "|  0.0|       0.0|[0.70488143283330...|\n",
      "|  0.0|       0.0|[0.61465640167466...|\n",
      "|  0.0|       0.0|[0.68648366948172...|\n",
      "|  0.0|       0.0|[0.73250362732005...|\n",
      "|  0.0|       0.0|[0.66110307678915...|\n",
      "|  0.0|       0.0|[0.68839699814029...|\n",
      "|  0.0|       0.0|[0.69670558196481...|\n",
      "|  0.0|       0.0|[0.82569919743834...|\n",
      "|  0.0|       0.0|[0.71424270202068...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "selected.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "233ef19a-8e09-4155-9928-04303a57533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = predictions.select(\"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65e4bf9b-b3de-4098-a507-9353b311dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|        4964|\n",
      "|  1.0|        1555|\n",
      "+-----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cm.groupby('label').agg({'label': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb88ab32-0820-4a68-99cf-37903bafa702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             5908|\n",
      "|       1.0|              611|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm.groupby('prediction').agg({'prediction': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d88d7f2b-fa8d-493a-8adf-d128773edfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8263537352354655"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.filter(cm.label == cm.prediction).count() / cm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ce3834a-7fc1-4046-8163-f5fa1db0ea90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 82.635%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def accuracy_m(model): \n",
    "    predictions = model.transform(test_data)\n",
    "    cm = predictions.select(\"label\", \"prediction\")\n",
    "    acc = cm.filter(cm.label == cm.prediction).count() / cm.count()\n",
    "    print(\"Model accuracy: %.3f%%\" % (acc * 100)) \n",
    "accuracy_m(model = linearModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a973975-dd75-412d-8319-4abd0391a0f4",
   "metadata": {},
   "source": [
    "## ROC Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17c18ff3-9e5a-4539-89c3-535722537b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8970407512870788\n",
      "areaUnderROC\n"
     ]
    }
   ],
   "source": [
    "### Use ROC \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(evaluator.evaluate(predictions))\n",
    "print(evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09efbc4-a40e-44ec-9369-d49c276130b3",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed0bc348-b076-4a8a-b6c3-d0f077e7f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5551c851-0b20-42a2-b3b4-8def98c4b831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/15 13:36:55 WARN BlockManager: Asked to remove block broadcast_115, which does not exist\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train model: 228.452 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import *\n",
    "start_time = time()\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train_data)\n",
    "# likely take a fair amount of time\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train model: %.3f seconds\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14e42779-fe20-48be-a0f6-6a6e4879eb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 378:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 85.688%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "accuracy_m(model = cvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ff91415-783c-441c-8463-9c03e2460c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_25b05cbc1d7d', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2,\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto',\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='featuresCol', doc='features column name.'): 'features',\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='fitIntercept', doc='whether to fit an intercept term.'): True,\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='labelCol', doc='label column name.'): 'label',\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0,\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='standardization', doc='whether to standardize the training features before fitting the model.'): True,\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5,\n",
       " Param(parent='LogisticRegression_25b05cbc1d7d', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d662e-a3ac-4d80-b798-32f45db53f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
